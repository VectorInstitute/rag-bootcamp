{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214d4de8-3a05-43dd-8a44-82c22570a553",
   "metadata": {},
   "source": [
    "# Amazon AWS S3 Search with LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e6b6",
   "metadata": {},
   "source": [
    "This example shows how to use the Python [LlamaIndex](https://www.llamaindex.ai/) to run a text-generation request on open-source LLMs and embedding models using the OpenAI SDK, then augment that request using documents stored in an Amazon AWS S3 bucket.\n",
    "\n",
    "### <u>Requirements</u>\n",
    "1. As you will accessing the LLMs and embedding models through Vector AI Engineering's Kaleidoscope Service (Vector Inference + Autoscaling), you will need to request a KScope API Key:\n",
    "- If using **VPN**:\n",
    "  \n",
    "  Visit [https://kscope.vectorinstitute.ai/](https://kscope.vectorinstitute.ai/) and select *Request API Key*.\n",
    "  \n",
    "- If running **without VPN**:\n",
    "\n",
    "  Run the following command (replace ```<user_id>``` and ```<password>```) from **within the cluster** to obtain the API Key. The ```access_token``` in the output is your KScope API Key.\n",
    "  ```bash\n",
    "  curl -X POST -d \"grant_type=password\" -d \"username=<user_id>\" -d \"password=<password>\" https://kscope.vectorinstitute.ai/token\n",
    "  ```\n",
    "2. After obtaining the `.env` configurations, make sure to create the ```.kscope.env``` file in your home directory (```/h/<user_id>```) and set the following env variables:\n",
    "- For local models through Kaleidoscope (KScope):\n",
    "    ```bash\n",
    "    export OPENAI_BASE_URL=\"https://kscope.vectorinstitute.ai/v1\"\n",
    "    export OPENAI_API_KEY=<kscope_api_key>\n",
    "    ```\n",
    "- For OpenAI models:\n",
    "   ```bash\n",
    "   export OPENAI_BASE_URL=\"https://api.openai.com/v1\"\n",
    "   export OPENAI_API_KEY=<openai_api_key>\n",
    "3. You will also need an Amazon AWS account, with some documents stored in a S3 bucket. Store your AWS credentials in a text file at `~/.aws/credentials`. This file must use the following format:\n",
    "  \n",
    "  ```\n",
    "    [default]\n",
    "    aws_access_key_id = YOUR_ACCESS_KEY\n",
    "    aws_secret_access_key = YOUR_SECRET_KEY\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4da1f",
   "metadata": {},
   "source": [
    "## Set up the RAG workflow environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a8f2e-bb4e-4355-9b0b-b6c291532656",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a6cae4-8a21-4f80-8087-15d1c0a897c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, Settings, StorageContext\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.node_parser import LangchainNodeParser\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.readers.s3 import S3Reader\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6a33a-7561-454f-a92b-ebeed14998fd",
   "metadata": {},
   "source": [
    "#### Load config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2102318d-0049-4338-91bc-a4d12b2781e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root folder of the rag_bootcamp repo to PYTHONPATH\n",
    "current_dir = Path().resolve()\n",
    "parent_dir = current_dir.parent\n",
    "sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from utils.load_secrets import load_env_file\n",
    "load_env_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84dd6f56-a4d0-4556-86e7-f65ca94b89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_BASE_URL = os.environ.get(\"OPENAI_BASE_URL\")\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecf9ac",
   "metadata": {},
   "source": [
    "#### Set up some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4e2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.text for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edd103",
   "metadata": {},
   "source": [
    "#### Make sure other necessary items are in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b61e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the AWS credentials are stored in ~/.aws/credentials\n",
    "try:\n",
    "    aws_credentials_file = Path.home() / \".aws/credentials\"\n",
    "    assert aws_credentials_file.exists()\n",
    "except:\n",
    "    sys.exit(f\"Unable to find your AWS credentials file at {aws_credentials_file}. Make sure this file exists and contains your AWS credentials.\\n\")\n",
    "\n",
    "# Make sure the AWS credentials are stored in the correct format\n",
    "try:\n",
    "    aws_credentials = open(aws_credentials_file, \"r\").read().strip()\n",
    "    assert aws_credentials.startswith(\"[default]\")\n",
    "    assert \"aws_access_key_id\" in aws_credentials\n",
    "    assert \"aws_secret_access_key\" in aws_credentials\n",
    "except Exception:\n",
    "    sys.exit(f\"\"\"Unable to load AWS credentials. Make sure your ~/.aws/credentials file is in the following format:\n",
    "[default]\n",
    "aws_access_key_id = YOUR_ACCESS_KEY\n",
    "aws_secret_access_key = YOUR_SECRET_KEY\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf67bd7a-99ab-4e6b-8eea-5eb8f294a290",
   "metadata": {},
   "source": [
    "#### Choose LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1adcbcd1-5fe9-44b1-80de-f2d0584d129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_MODEL_NAME = \"Meta-Llama-3.1-8B-Instruct\"\n",
    "EMBEDDING_MODEL_NAME = \"BAAI/bge-base-en-v1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558afb",
   "metadata": {},
   "source": [
    "## Start with a basic generation request without RAG augmentation\n",
    "\n",
    "Let's start by asking Llama-3.1 a difficult, domain-specific question we don't expect it to have an answer to. A simple question like \"*What is the capital of France?*\" is not a good question here, because that's world knowledge that we expect the LLM to know.\n",
    "\n",
    "Instead, we want to ask it a question that is domain-specific and it won't know the answer to. A good example would be an obscure detail buried deep within a company's annual report. For example:\n",
    "\n",
    "*How many Vector scholarships in AI were awarded in 2022?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6133a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many Vector scholarships in AI were awarded in 2022?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295a6a9-76bc-4779-8346-c1cfdea30a3b",
   "metadata": {},
   "source": [
    "## Now send the query to the open source model using KScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a3a3949-bc8f-4244-ab12-4759e296aa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "assistant: I don't have access to real-time data or specific information about the number of Vector scholarships in AI awarded in 2022. For the most accurate and up-to-date information, I recommend checking directly with Vector Institute or their official website. They would have the most current details on their scholarship programs and awards.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAILike(\n",
    "    model=GENERATOR_MODEL_NAME,\n",
    "    is_chat_model=True,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    api_base=GENERATOR_BASE_URL,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "message = [\n",
    "    ChatMessage(\n",
    "        role=\"user\",\n",
    "        content=query\n",
    "    )\n",
    "]\n",
    "try:\n",
    "    result = llm.chat(message)\n",
    "    print(f\"Result: \\n\\n{result}\")\n",
    "except Exception as err:\n",
    "    if \"Error code: 503\" in err.message:\n",
    "        print(f\"The model {GENERATOR_MODEL_NAME} is not ready yet.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1c200",
   "metadata": {},
   "source": [
    "Without additional information, Llama-3.1 is unable to answer the question correctly. **Vector in fact awarded 109 AI scholarships in 2022.** Fortunately, we do have that information available in Vector's 2021-22 Annual Report, which is available in AWS S3 bucket. Let's see how we can use RAG to augment our question with a document search (stored in S3) and get the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ea68",
   "metadata": {},
   "source": [
    "## Ingestion: Retrieve and store the documents from an Amazon S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d0304",
   "metadata": {},
   "source": [
    "We've added Vector's 2021-22 Annual Report pdf in an Amazon S3 bucket:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c19ee43d-b312-4e06-a2a0-aae2e6f566d2",
   "metadata": {},
   "source": [
    "![aws-s3-snapshot](imgs/aws-s3-snapshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a865f-38f6-4db9-bb98-03046403ccc6",
   "metadata": {},
   "source": [
    "#### Load these documents using S3Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb063591-d7a8-44bd-b160-c993df65280b",
   "metadata": {},
   "source": [
    "Fortunately, there is a simple S3 utility available via [LlamaHub](https://www.llamahub.ai/), a registry of open-source data connectors that you can easily plug into any LlamaIndex application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5710c72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 42\n"
     ]
    }
   ],
   "source": [
    "loader = S3Reader(bucket='vector-rag-bootcamp-v2')\n",
    "docs = loader.load_data()\n",
    "print(f\"Number of source documents: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e831a534-a17f-4eaf-98f3-8d3b56260ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 228\n"
     ]
    }
   ],
   "source": [
    "# Split the documents into smaller chunks\n",
    "parser = LangchainNodeParser(RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=32))\n",
    "chunks = parser.get_nodes_from_documents(docs)\n",
    "print(f\"Number of text chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b2f772-e126-4ef9-9b10-fafc150f2ec4",
   "metadata": {},
   "source": [
    "#### Define the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3660c8d9-949f-4e27-ab16-cf01dcfa9c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the embeddings model...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Setting up the embeddings model...\")\n",
    "embeddings = HuggingFaceEmbedding(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    device='cuda',\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855bd7da-444c-4f69-82ea-0be42197f504",
   "metadata": {},
   "source": [
    "#### Set LLM and embedding model [recommended for LlamaIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd48cd82-3ee2-4fba-930f-78f474eddb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7162fb-a410-47c0-a0be-667c837c53b4",
   "metadata": {},
   "source": [
    "## Retrieval: Make the document chunks available via a retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f94d3-1a91-415f-a05c-3932e105bd85",
   "metadata": {},
   "source": [
    "The retriever will identify the document chunks that most closely match our original query. (This takes about 1-2 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90eb92e7-c991-4af5-bc72-984a82c33b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_model_dim(embed_model):\n",
    "    embed_out = embed_model.get_text_embedding(\"Dummy Text\")\n",
    "    return len(embed_out)\n",
    "\n",
    "faiss_dim = get_embed_model_dim(embeddings)\n",
    "faiss_index = faiss.IndexFlatL2(faiss_dim)\n",
    "\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex(chunks, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c63ae1c1-790c-449e-8ceb-fa7f03537c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=10)\n",
    "\n",
    "# Retrieve the most relevant context from the vector store based on the query\n",
    "retrieved_docs = retriever.retrieve(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b0c8e0-3e0c-4852-a9e7-e0c53fcda58b",
   "metadata": {},
   "source": [
    "Let's see what results it found. Important to note, these results are in the order the retriever thought were the best matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48779d92-08f1-4a36-a970-3cbb55ce2401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "26 \n",
      "  VECTOR SCHOLARSHIPS IN \n",
      "AI ATTRACT TOP TALENT TO ONTARIO UNIVERSITIES \n",
      "109 \n",
      "Vector Scholarships in AI awarded \n",
      "34 \n",
      "Programs \n",
      "13 \n",
      "Universities \n",
      "351 \n",
      "Scholarships awarded since the \n",
      "program launched in 2018 Supported with funding from the Province of Ontario, the Vector Institute Scholarship in Artifcial Intelligence (VSAI) helps Ontario universities to attract the best and brightest students to study in AI-related master’s programs. \n",
      "Scholarship recipients connect directly with leading\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "5 \n",
      "Annual Report 2021–22 Vector Institute\n",
      "SPOTLIGHT ON FIVE YEARS OF AI \n",
      "LEADERSHIP FOR CANADIANS \n",
      "SINCE THE VECTOR INSTITUTE WAS FOUNDED IN 2017: \n",
      "2,080+ \n",
      "Students have graduated from \n",
      "Vector-recognized AI programs and \n",
      "study paths $6.2 M \n",
      "Scholarship funds committed to \n",
      "students in AI programs 3,700+ \n",
      "Postings for AI-focused jobs and \n",
      "internships ofered on Vector’s \n",
      "Digital Talent Hub $103 M \n",
      "In research funding committed to \n",
      "Vector-afliated researchers \n",
      "94 \n",
      "Research awards earned by\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "studies in a Vector-recognized AI-related master’s program or other study paths in AI — both a record number and a 27 per cent increase over the previous year. Last year also saw more than 1,000 new graduates from AI master’s programs in Ontario; a milestone achieved ahead of the province’s 2023 target. These skilled AI graduates will hold an envied role in the workforce of the future. Further, our research community has now grown to more than 700, whose infuence continues to grow; they published more than\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Arrows indicate year-over-year (YoY) directional change since 2020–21 The complete Ontario AI Snapshot for 2021–22 will be available soon on the Vector Institute website at vectorinstitute.ai. \n",
      "YoY \n",
      "22,458 \n",
      "AI jobs created YoY \n",
      "59,673 \n",
      "AI jobs retained YoY \n",
      "1,775 \n",
      "New AI Master’s & study path enrolments YoY \n",
      "1,007 \n",
      "New AI Master’s graduates from Vector-recognized programs \n",
      "YoY \n",
      "66 \n",
      "New AI-related patents fled across Canada YoY \n",
      "$2.86 BILLION \n",
      "In AI-related VC investment * YoY \n",
      "273\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "23 \n",
      "RESEARCH AWARDS AND \n",
      "ACHIEVEMENTS \n",
      "Each year, members of Vector’s research community \n",
      "are recognized for outstanding contributions to AI and machine learning felds. Highlights of 2021–22 include: \n",
      "GLOBAL REACH OF VECTOR \n",
      "RESEARCHERS AND THEIR WORK \n",
      "Vector researchers published papers, gave \n",
      "presentations, or led workshops at many of the top AI conferences this year, including NeurIPS, CVPR, ICLR, ICML, and ACM FAccT. \n",
      "380+ Research papers presented at\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "\n",
      "and Universities \n",
      "1,007 \n",
      "graduates from recognized AI-master’s programs at Ontario universities, exceeding the province’s target to graduate 1,000 AI master’s students per year by 2023 ahead of schedule\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 7:\n",
      "\n",
      "“A large part of why I decided to return to Toronto from California was due to how strong Vector is as an institute in AI and the fact that there are so many great professors here that I can learn from. Being in this ecosystem has been a really great help for both my professional and academic journey.” \n",
      "Alex Cui, Vector Scholarship in AI Recipient 2021–22 \n",
      "“The scholarship funding from the Vector Institute\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 8:\n",
      "\n",
      "35 \n",
      "Annual Report 2021–22 Vector Institute\n",
      " \n",
      " AI ENGINEERING   \n",
      "Vector is engineering new frontiers \n",
      "of AI application in industry, health and government Knowledge transfer \n",
      "Working directly with AI \n",
      "professionals to build their capacity and expertise \n",
      "Hands-on guidance \n",
      "Collaborating on real-\n",
      "world projects to accelerate successful AI deployment \n",
      "Amplifying research \n",
      "Enabling w\n",
      "orld-class \n",
      "researchers to unlock and share \n",
      "AI progress to beneft a global community Enhancing Canada’s AI infrastructure\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 9:\n",
      "\n",
      "Talent and Research was renewed in the federal Budget 2021, and funding support associated with that renewal is expected to begin in 2022–23. The federal Budget 2021 also announced support for each of the national AI institutes to accelerate the translation of AI research into commercial or other innovations, and this funding started at the end of 2021–22. \n",
      "The Vector Institute’s audited fnancial statements for \n",
      "the 2021–22 fscal year are available on our website . \n",
      "STATEMENT OF FINANCIAL POSITION\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 10:\n",
      "\n",
      "25 \n",
      "  \n",
      " \n",
      "   \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "   \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      "  \n",
      " \n",
      "  \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " VECTOR RECOGNIZED UNIVERSITY \n",
      "PROGRAMS ARE BUILDING ONTARIO’S AI WORKFORCE OF THE FUTURE \n",
      "26 \n",
      "Recognized AI master’s programs  \n",
      "at 11 Ontario universities \n",
      "7 New degree programs \n",
      "19 Programs with updated curricula in \n",
      "AI-specifc minors, concentrations and courses \n",
      "A\n",
      "s part of its work to help develop a steady pipeline of AI-skilled talent,\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1690e",
   "metadata": {},
   "source": [
    "## Now send the query to the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23499f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "109 Vector Scholarships in AI were awarded.\n"
     ]
    }
   ],
   "source": [
    "query_engine = RetrieverQueryEngine(retriever=retriever)\n",
    "result = query_engine.query(query)\n",
    "print(f\"Result: \\n\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5480d010-965b-45bb-8fc5-216ad5b7e0ce",
   "metadata": {},
   "source": [
    "The model provides the correct answer (109) using the retrieved information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_dataloaders",
   "language": "python",
   "name": "rag_dataloaders"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
