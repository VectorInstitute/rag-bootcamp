{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d86f6cd",
   "metadata": {
    "id": "3d86f6cd"
   },
   "source": [
    "# Web Search with LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e6b6",
   "metadata": {
    "id": "4168e6b6"
   },
   "source": [
    "This example shows how to use the Python [LlamaIndex](https://docs.llamaindex.ai/en/stable/) library to run a text-generation request on open-source LLMs and embedding models using the OpenAI SDK, then augment that request using results from Google web search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4da1f",
   "metadata": {
    "id": "22e4da1f"
   },
   "source": [
    "## Set up the RAG workflow environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rguJCjsb3uEi",
   "metadata": {
    "id": "rguJCjsb3uEi"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/VectorInstitute/rag_bootcamp /tmp/rag_bootcamp\n",
    "!cp -ar /tmp/rag_bootcamp/document_search/* ./\n",
    "\n",
    "# Install langchain and LlamaIndex packages, filtering out version numbers\n",
    "!grep -Eo '^(langchain|llama)[^=]*' \\\n",
    "    /tmp/rag_bootcamp/envs/rag_dataloaders/requirements.txt > \\\n",
    "    /tmp/requirements.txt\n",
    "!pip3 install -r /tmp/requirements.txt\n",
    "!pip3 install faiss-cpu\n",
    "!pip3 install googlesearch-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K-kdq5NT3x4i",
   "metadata": {
    "id": "K-kdq5NT3x4i"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TODO: fill in the two following lines\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://.../v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a8826-fcd8-439b-8c5d-f9047fbe5c0e",
   "metadata": {
    "id": "3e9a8826-fcd8-439b-8c5d-f9047fbe5c0e"
   },
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea754e1b-3f61-4562-839f-a999db8e926e",
   "metadata": {
    "id": "ea754e1b-3f61-4562-839f-a999db8e926e"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f637730",
   "metadata": {
    "id": "2f637730"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from llama_index.core import Settings, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.node_parser import LangchainNodeParser\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.readers import StringIterableReader\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae9862-6b55-4556-b38a-fc7ba55ee37f",
   "metadata": {
    "id": "41ae9862-6b55-4556-b38a-fc7ba55ee37f"
   },
   "source": [
    "#### Load config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c528521-8bb4-49c6-b181-e0ecd6862e3e",
   "metadata": {
    "id": "4c528521-8bb4-49c6-b181-e0ecd6862e3e"
   },
   "outputs": [],
   "source": [
    "GENERATOR_BASE_URL = os.environ[\"OPENAI_BASE_URL\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecf9ac",
   "metadata": {
    "id": "12ecf9ac"
   },
   "source": [
    "#### Set up some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4e2417",
   "metadata": {
    "id": "dd4e2417"
   },
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.text for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e47ff-77bc-4ecd-9e7f-8abc60fa8d81",
   "metadata": {
    "id": "7c9e47ff-77bc-4ecd-9e7f-8abc60fa8d81"
   },
   "source": [
    "#### Choose LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84b28b5e-d9d9-4788-9887-5c71aedfd8a1",
   "metadata": {
    "id": "84b28b5e-d9d9-4788-9887-5c71aedfd8a1"
   },
   "outputs": [],
   "source": [
    "GENERATOR_MODEL_NAME = \"Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "## Select one of the two options:\n",
    "## - \"all-MiniLM-L6-v2\" (22M parameters)\n",
    "## - \"bge-base-en-v1.5\" (110M parameters)\n",
    "\n",
    "# EMBEDDING_MODEL_NAME = \"bge-base-en-v1.5\"\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558afb",
   "metadata": {
    "id": "1e558afb"
   },
   "source": [
    "## Start with a basic generation request without RAG augmentation\n",
    "\n",
    "Let's start by asking Llama-3.1 a question about recent events that it doesn't know about, something that happened after it finished training. At the time I'm writing this notebook in November 2024, Llama3 doesn't know who won the last World Series of baseball.\n",
    "\n",
    "*Who won the 2024 World Series of baseball?*\n",
    "\n",
    "**The correct answer is the Los Angeles Dodgers won in October 2024.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6133a928",
   "metadata": {
    "id": "6133a928"
   },
   "outputs": [],
   "source": [
    "query = \"Who won the 2024 World Series of baseball?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bccaf41",
   "metadata": {
    "id": "3bccaf41"
   },
   "source": [
    "## Now send the query to the open source model using KScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40c2663f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40c2663f",
    "outputId": "fe7c3378-6246-4718-a88d-612ae2ce094e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "assistant: I don't have the ability to predict the future or know the outcome of future events, including the 2024 World Series. The 2024 World Series has not yet occurred, and I don't have any information about it. I can provide information about past World Series winners, though. Would you like to know more about that?\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAILike(\n",
    "    model=GENERATOR_MODEL_NAME,\n",
    "    is_chat_model=True,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    api_base=GENERATOR_BASE_URL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    api_version=\"1\"\n",
    ")\n",
    "message = [\n",
    "    ChatMessage(\n",
    "        role=\"user\",\n",
    "        content=query\n",
    "    )\n",
    "]\n",
    "try:\n",
    "    result = llm.chat(message)\n",
    "    print(f\"Result: \\n\\n{result}\")\n",
    "except Exception as err:\n",
    "    if \"Error code: 503\" in err.message:\n",
    "        print(f\"The model {GENERATOR_MODEL_NAME} is not ready yet.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1c200",
   "metadata": {
    "id": "e6e1c200"
   },
   "source": [
    "Llama-3.1 admits that it doesn't know the answer, since according to the model it's a future event.\n",
    "\n",
    "Let's see how we can use RAG to augment our question with a Google web search and get the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ea68",
   "metadata": {
    "id": "0255ea68"
   },
   "source": [
    "## Ingestion: Do a Google web search for the query and obtain the necessary information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d0304",
   "metadata": {
    "id": "ba9d0304"
   },
   "source": [
    "Parse through all the websites returned by a Google search, break them up into smaller digestible chunks, then encode them as vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5710c72d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5710c72d",
    "outputId": "43943e5f-156d-42bf-9d5b-bc4d5a240bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 9\n",
      "Number of text chunks: 524\n"
     ]
    }
   ],
   "source": [
    "# Do a Google web search and store the results in a documents list\n",
    "web_documents = []\n",
    "for result_url in list(search(query))[:10]:\n",
    "    try:\n",
    "        response = requests.get(result_url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    except:\n",
    "        # Skip if connection error\n",
    "        continue\n",
    "\n",
    "    web_documents.append(soup.get_text())\n",
    "\n",
    "docs = StringIterableReader().load_data(texts=web_documents)\n",
    "print(f\"Number of source documents: {len(docs)}\")\n",
    "\n",
    "# Split the documents into smaller chunks\n",
    "parser = LangchainNodeParser(RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=32))\n",
    "chunks = parser.get_nodes_from_documents(docs)\n",
    "print(f\"Number of text chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706de010-2ad6-4e89-a307-2ad30497fc07",
   "metadata": {
    "id": "706de010-2ad6-4e89-a307-2ad30497fc07"
   },
   "source": [
    "#### Define the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f69ffb-44f0-411f-bdc3-75efe8fb0d23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54f69ffb-44f0-411f-bdc3-75efe8fb0d23",
    "outputId": "2a97d00f-8fa9-4d9f-aae7-9c38f4da6864"
   },
   "outputs": [],
   "source": [
    "print(f\"Setting up the embeddings model {EMBEDDING_MODEL_NAME} from {GENERATOR_BASE_URL}\")\n",
    "embeddings = OpenAIEmbedding(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    embed_batch_size=128,\n",
    "    api_base=GENERATOR_BASE_URL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f1024-90cf-424a-9372-9dec784bc258",
   "metadata": {
    "id": "566f1024-90cf-424a-9372-9dec784bc258"
   },
   "source": [
    "#### Set LLM and embedding model [recommended for LlamaIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7484523-4a7d-43de-9c9c-bf46425e83ac",
   "metadata": {
    "id": "b7484523-4a7d-43de-9c9c-bf46425e83ac"
   },
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ed6a7-17a1-49f3-b406-bf7c3aec4595",
   "metadata": {
    "id": "736ed6a7-17a1-49f3-b406-bf7c3aec4595"
   },
   "source": [
    "## Retrieval: Make the document chunks available via a retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a096b-85b9-45db-a9d6-dd1fde37358e",
   "metadata": {
    "id": "b14a096b-85b9-45db-a9d6-dd1fde37358e"
   },
   "source": [
    "The retriever will identify the document chunks that most closely match our original query. (This takes about 1-2 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "996df356-db4f-4e1e-90cb-9414ed0d2ec2",
   "metadata": {
    "id": "996df356-db4f-4e1e-90cb-9414ed0d2ec2"
   },
   "outputs": [],
   "source": [
    "def get_embed_model_dim(embed_model):\n",
    "    embed_out = embed_model.get_text_embedding(\"Dummy Text\")\n",
    "    return len(embed_out)\n",
    "\n",
    "faiss_dim = get_embed_model_dim(embeddings)\n",
    "faiss_index = faiss.IndexFlatL2(faiss_dim)\n",
    "\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex(chunks, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "891457d4-60cb-470c-b11a-3840eb85c882",
   "metadata": {
    "id": "891457d4-60cb-470c-b11a-3840eb85c882"
   },
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "# Retrieve the most relevant context from the vector store based on the query\n",
    "retrieved_docs = retriever.retrieve(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa43e8-cf9b-42f2-bfb4-b12c00370480",
   "metadata": {
    "id": "e5aa43e8-cf9b-42f2-bfb4-b12c00370480"
   },
   "source": [
    "Let's see what results it found. Important to note, these results are in the order the retriever thought were the best matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dffa44d-c61c-4d35-835b-eb3aa9989f7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dffa44d-c61c-4d35-835b-eb3aa9989f7a",
    "outputId": "89a79e6b-2409-43e5-fab4-a3b908004ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "The 2024 World Series was the championship series of Major League Baseball's (MLB) 2024 season. The 120th edition of the World Series, it was a best-of-seven playoff between the National League (NL) champion Los Angeles Dodgers and the American League (AL) champion New York Yankees. It was the Dodgers' first World Series appearance and win since 2020, and the Yankees' first World Series appearance since 2009. The series began on October 25 and ended on October 30 with the Dodgers winning in five\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Blue Jays1994 - Not played (due to strike)1995 - Atlanta Braves1996 - New York Yankees1997 - Florida Marlins1998 - New York Yankees1999 - New York Yankees2000 - New York Yankees2001 - Arizona Diamondbacks2002 - Anaheim Angels2003 - Florida Marlins2004 - Boston Red Sox2005 - Chicago White Sox2006 - St. Louis Cardinals2007 - Boston Red Sox2008 - Philadelphia Phillies2009 - New York Yankees2010 - San Francisco Giants2011 - St. Louis Cardinals2012 - San Francisco Giants2013 - Boston Red Sox2014 - San Francisco\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "^ Rosvoglou, Chris (October 30, 2024). \"Yankees Legend Had Horrendous First Pitch For Game 4 Of World Series\". The Spun.\n",
      "\n",
      "^ Phillips, Gary (October 26, 2024). \"Luis Gil will start Game 4 of World Series for Yankees\". New York Daily News.\n",
      "\n",
      "^ Doolittle, Bradford (October 29, 2024). \"Dodgers eye World Series sweep with, yes, a bullpen game\". ESPN.com. Retrieved October 29, 2024.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "- New York Yankees1954 - New York Giants1955 - Brooklyn Dodgers1956 - New York Yankees1957 - Milwaukee Braves1958 - New York Yankees1959 - Los Angeles Dodgers1960 - Pittsburgh Pirates1961 - New York Yankees1962 - New York Yankees1963 - Los Angeles Dodgers1964 - St. Louis Cardinals1965 - Los Angeles Dodgers1966 - Baltimore Orioles1967 - St. Louis Cardinals1968 - Detroit Tigers1969 - New York Mets1970 - Baltimore Orioles1971 - Pittsburgh Pirates1972 - Oakland Athletics1973 - Oakland Athletics1974 - Oakland\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "Oakland Athletics1974 - Oakland Athletics1975 - Cincinnati Reds1976 - Cincinnati Reds1977 - New York Yankees1978 - New York Yankees1979 - Pittsburgh Pirates1980 - Philadelphia Phillies1981 - Los Angeles Dodgers1982 - St. Louis Cardinals1983 - Baltimore Orioles1984 - Detroit Tigers1985 - Kansas City Royals1986 - New York Mets1987 - Minnesota Twins1988 - Los Angeles Dodgers1989 - Oakland Athletics1990 - Cincinnati Reds1991 - Minnesota Twins1992 - Toronto Blue Jays1993 - Toronto Blue Jays1994 - Not played\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e44d26-fccb-480e-9ad2-2c48aa7dcc92",
   "metadata": {
    "id": "d7e44d26-fccb-480e-9ad2-2c48aa7dcc92"
   },
   "source": [
    "## Now send the query to the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab480021-1266-45c9-b4ba-45d4c22dd5bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab480021-1266-45c9-b4ba-45d4c22dd5bc",
    "outputId": "30f19ffb-5b9c-43e1-d341-132af712ba42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "The Los Angeles Dodgers won the championship in five games.\n"
     ]
    }
   ],
   "source": [
    "query_engine = RetrieverQueryEngine(retriever=retriever)\n",
    "result = query_engine.query(query)\n",
    "print(f\"Result: \\n\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d727ce-487c-447a-91b1-56616b02f557",
   "metadata": {
    "id": "98d727ce-487c-447a-91b1-56616b02f557"
   },
   "source": [
    "The model provides the correct answer based on the information from the web."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
